category,prompt,task
introduce,"**An evaluation of music emotion recognition datasets** In this interactive module, you will be asked to annotate and evaluate the quality of open-access data used in Music Emotion Recognition (MER) studies. The module draws upon two highly influential papers in the Data Quality literature by Gebru et al. (2019) and Wang & Strong (1996), either adapting or directly adopting questions in an effort to improve documentation surrounding MER datasets. ",introduce
introduce,"**An evaluation of music emotion recognition datasets** In the first stage, you will be asked to fill in information surrounding the creators and design of the dataset. These questions come from Datasheets for Datasets by Gebru et al. (2019). In a second stage, you will be asked to rate several data quality dimension items on a scale from 1 = poor to 5 = impeccable. ",introduce
motivation,**For what purpose was the dataset created?** Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description.,annotate
motivation,"**Who created this dataset?** (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?",annotate
motivation,"**What support was needed to make this dataset?** (e.g. who funded the creation of the dataset? If there is an associated grant, provide the name of the grantor and the grant name and number, or if it was supported by a company or government agency, give those details.)",annotate
intrinsic,"**The task draws from relevant theories.** Does the task draw from prevailing theories of emotion? Are any compromises made, or inconsistencies introduced, when adapting theory for the research task?",evaluate
intrinsic,"**Analyses were conducted to assess the reliability of results.** Were additional analyses performed for validation (e.g., interrater reliability, cross-validation?) Do decisions give the impression these results are generalizable? ",evaluate
intrinsic,"**Study design decisions provide an impression that the study results are believable and replicable.** Does the combination of decisions about the measurement construct; participant recruitment; stimulus, feature, and model selection lead to an impression that the study conclusions are appropriate and believable?",evaluate
intrinsic,**The study appears to be reputable when considering the journal and readership/citation metrics.** ,evaluate
accessibility,"**The data from this project are publicly available.** Do any barriers exist that could impact the reproducibility of the project? (e.g., copyright issues, lack of documentation, poor repository management).",evaluate
accessibility,"**The dataset is self-contained, or links to otherwise external resources (e.g., websites, tweets, other datasets).** If it links to or relies on external resources, a) are there guarantees that they will exist, and remain constant, over time; b) are there official archival versions of the complete dataset (i.e., including the external resources as they existed at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees) associated with any of the external resources that might apply to a future user?",evaluate
accessibility,**Do users require special permissions to access the data?** Are costs associated with the creation of the dataset reported?,evaluate
contextual,"**Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?** If the dataset is a sample, then what is the larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If so, please describe how this representativeness was validated/verified. If it is not representative of the larger set, please describe why not (e.g., to cover a more diverse range of instances, because instances were withheld or unavailable).",evaluate
contextual,"**If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)?**",evaluate
contextual,**The dataset reflects functional open data practices.** How easily accessible is the dataset to new users?,evaluate
contextual,**The dataset fills a gap in the literature.**,evaluate
contextual,"**Is the public-facing dataset available in partial or complete form?** In other words, is enough data provided that the analyses reported in the accompanying paper can be reproduced? ",evaluate
contextual,"**How many observations of each type of instance are available?** e.g., stimuli, participants, annotations.",evaluate
representational,"**The dataset documentation is complete and clearly understandable.** Is sufficient information provided to understand how data are stored (e.g., repository structure and filenames), represented (column names, data, and metadata), and analyzed (preprocessing/analysis scripts)?",evaluate
representational,"**The data are represented concisely.** Are data provided in a human-readable format? Are redundant observations, verbose labels, or missing values/outliers accounted for in preprocessing and/or documentation?",evaluate
representational,"**Measured constructs are represented and applied in a manner that is both internally consistent within the study, and externally consistent with other studies.** In other words, are frameworks employed consistently employed throughout the study, as well as with other studies in the literature? ",evaluate
representational,"**What demographic/level of expertise do the annotators represent?** Does the design of study account for differences in expertise, primary language, demographics? If so, is this information available to users of the dataset?",evaluate
debrief,"**Thank you** Thank you for your time. Further reading:
Wang, R. Y., & Strong, D. M. (1996). Beyond accuracy: What data quality means to data consumers. Journal of management information systems, 12(4), 5-33.
Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., & Crawford, K. (2021). Datasheets for datasets. Communications of the ACM, 64(12), 86-92.
",debrief
